{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.9105,learning rate 0.001\n",
      "Iter 1,Testing Accuracy 0.9255,learning rate 0.00095\n",
      "Iter 2,Testing Accuracy 0.9332,learning rate 0.0009025\n",
      "Iter 3,Testing Accuracy 0.9382,learning rate 0.000857375\n",
      "Iter 4,Testing Accuracy 0.9413,learning rate 0.00081450626\n",
      "Iter 5,Testing Accuracy 0.9456,learning rate 0.0007737809\n",
      "Iter 6,Testing Accuracy 0.9474,learning rate 0.0007350919\n",
      "Iter 7,Testing Accuracy 0.9492,learning rate 0.0006983373\n",
      "Iter 8,Testing Accuracy 0.9513,learning rate 0.0006634204\n",
      "Iter 9,Testing Accuracy 0.9535,learning rate 0.0006302494\n",
      "Iter 10,Testing Accuracy 0.9559,learning rate 0.0005987369\n",
      "Iter 11,Testing Accuracy 0.9571,learning rate 0.0005688001\n",
      "Iter 12,Testing Accuracy 0.9592,learning rate 0.0005403601\n",
      "Iter 13,Testing Accuracy 0.96,learning rate 0.0005133421\n",
      "Iter 14,Testing Accuracy 0.9613,learning rate 0.000487675\n",
      "Iter 15,Testing Accuracy 0.9619,learning rate 0.00046329122\n",
      "Iter 16,Testing Accuracy 0.962,learning rate 0.00044012666\n",
      "Iter 17,Testing Accuracy 0.9639,learning rate 0.00041812033\n",
      "Iter 18,Testing Accuracy 0.9647,learning rate 0.00039721432\n",
      "Iter 19,Testing Accuracy 0.9653,learning rate 0.0003773536\n",
      "Iter 20,Testing Accuracy 0.9656,learning rate 0.00035848594\n",
      "Iter 21,Testing Accuracy 0.9673,learning rate 0.00034056162\n",
      "Iter 22,Testing Accuracy 0.9676,learning rate 0.00032353355\n",
      "Iter 23,Testing Accuracy 0.9678,learning rate 0.00030735688\n",
      "Iter 24,Testing Accuracy 0.9685,learning rate 0.000291989\n",
      "Iter 25,Testing Accuracy 0.969,learning rate 0.00027738957\n",
      "Iter 26,Testing Accuracy 0.9685,learning rate 0.0002635201\n",
      "Iter 27,Testing Accuracy 0.9694,learning rate 0.00025034408\n",
      "Iter 28,Testing Accuracy 0.9693,learning rate 0.00023782688\n",
      "Iter 29,Testing Accuracy 0.9705,learning rate 0.00022593554\n",
      "Iter 30,Testing Accuracy 0.9701,learning rate 0.00021463877\n",
      "Iter 31,Testing Accuracy 0.9713,learning rate 0.00020390682\n",
      "Iter 32,Testing Accuracy 0.9708,learning rate 0.00019371149\n",
      "Iter 33,Testing Accuracy 0.9721,learning rate 0.0001840259\n",
      "Iter 34,Testing Accuracy 0.9713,learning rate 0.00017482461\n",
      "Iter 35,Testing Accuracy 0.9722,learning rate 0.00016608338\n",
      "Iter 36,Testing Accuracy 0.9726,learning rate 0.00015777921\n",
      "Iter 37,Testing Accuracy 0.9732,learning rate 0.00014989026\n",
      "Iter 38,Testing Accuracy 0.9726,learning rate 0.00014239574\n",
      "Iter 39,Testing Accuracy 0.9737,learning rate 0.00013527596\n",
      "Iter 40,Testing Accuracy 0.9737,learning rate 0.00012851215\n",
      "Iter 41,Testing Accuracy 0.9724,learning rate 0.00012208655\n",
      "Iter 42,Testing Accuracy 0.9737,learning rate 0.00011598222\n",
      "Iter 43,Testing Accuracy 0.9737,learning rate 0.00011018311\n",
      "Iter 44,Testing Accuracy 0.9742,learning rate 0.000104673956\n",
      "Iter 45,Testing Accuracy 0.9741,learning rate 9.944026e-05\n",
      "Iter 46,Testing Accuracy 0.9748,learning rate 9.446825e-05\n",
      "Iter 47,Testing Accuracy 0.9748,learning rate 8.974483e-05\n",
      "Iter 48,Testing Accuracy 0.9743,learning rate 8.525759e-05\n",
      "Iter 49,Testing Accuracy 0.9752,learning rate 8.099471e-05\n",
      "Iter 50,Testing Accuracy 0.9745,learning rate 7.6944976e-05\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets('./MNIST_data/', one_hot=True)\n",
    "\n",
    "# 定义每个批次大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "lr = tf.Variable(0.001, dtype=tf.float32)\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 500], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([500]) + 0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "L1_drop = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([500, 300], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([300]) + 0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop, W2) + b2)\n",
    "L2_drop = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "\n",
    "# 输出层\n",
    "W3 = tf.Variable(tf.truncated_normal([300, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L2_drop, W3) + b3)\n",
    "\n",
    "\n",
    "# 交叉熵\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.AdadeltaOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "# 求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(51):\n",
    "        sess.run(tf.assign(lr, 0.001 * (0.95 ** epoch)))\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys, keep_prob:1.0})\n",
    "        \n",
    "        learning_rate = sess.run(lr)\n",
    "        test_acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0})\n",
    "        print('Iter ' + str(epoch) + ',Testing Accuracy ' + str(test_acc) + \",learning rate \" + str(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
